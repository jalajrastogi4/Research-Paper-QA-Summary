# ===== OpenAI Configuration =====
OPENAI_API_KEY=""

# ===== Langfuse Observability (Optional) =====
LANGFUSE_PUBLIC_KEY=""
LANGFUSE_SECRET_KEY=""
LANGFUSE_BASE_URL="https://cloud.langfuse.com"

# ===== Database Configuration =====
# Format: postgresql+asyncpg://username:password@host:port/database
# Example: postgresql+asyncpg://langgraph_admin:MyPass123@langgraph-db.abc123.us-east-1.rds.amazonaws.com:5432/langgraph_research
DATABASE_URL=""

# Database Connection Pool Settings
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
DB_POOL_RECYCLE=3600
DB_POOL_TIMEOUT=30

# ===== Redis & Celery Configuration =====
# Format: redis://default:password@host:port
# Example: redis://default:AXbKc...xyz@us1-happy-mantis-12345.upstash.io:6379
REDIS_URL=""
CELERY_BROKER_URL=""  # Leave empty to use REDIS_URL
CELERY_RESULT_BACKEND_URL=""  # Leave empty to use REDIS_URL

# ===== Pinecone Vector Store =====
PINECONE_API_KEY=""
PINECONE_INDEX_NAME="research-papers"
PINECONE_ENVIRONMENT="us-east-1"

# ===== Model Configuration =====
LLM_MODEL="gpt-4-turbo"
EMBEDDINGS_MODEL="text-embedding-3-small"
LLM_TEMPERATURE=0.0

# ===== Retrieval and Chunking =====
CHUNK_SIZE=1000
CHUNK_OVERLAP=100
RETRIEVAL_DOCS=3
SECTION_PARSER_LIMIT=5000

# ===== Hallucination Detection Weights =====
CITATION_SCORE=0.4
LLM_SCORE=0.4
CONSISTENCY_SCORE=0.2

# ===== Directory Configuration =====
CHROMADB_DIR="data/chromadb"  # Legacy - will be replaced by Pinecone
LOGS_DIR="logs"
ARXIV_DIR="data/arxiv"
RENDER_DISK_PATH="/data"  # Render persistent disk mount path (for production)

# ===== Application Settings =====
ENVIRONMENT="development"  # Options: development, staging, production